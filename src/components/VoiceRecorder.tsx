import React, { useRef, useEffect, useState, memo } from "react";
import { IconButton, Box, Tooltip } from "@mui/material";
import { Mic as MicIcon, Stop as StopIcon } from "@mui/icons-material";
import { startTranscribeStreaming } from "../services/amplifyService";

interface VoiceRecorderProps {
  onTranscriptionResult?: (text: string) => void;
  disabled?: boolean;
}

const VoiceRecorder: React.FC<VoiceRecorderProps> = ({
  onTranscriptionResult,
  disabled = false,
}) => {
  // ReactçŠ¶æ…‹ç®¡ç†ã‚’ä½¿ç”¨
  const [isRecording, setIsRecording] = useState(false);

  const mediaStreamRef = useRef<MediaStream | null>(null);
  const isStoppedManuallyRef = useRef(false);
  const accumulatedTranscriptRef = useRef<string>("");
  const transcribeAbortControllerRef = useRef<AbortController | null>(null);
  const isInitializedRef = useRef(false);

  const initializeRecorder = async () => {
    try {
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        throw new Error("ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯éŸ³å£°éŒ²éŸ³ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“");
      }
      const { createTranscribeStreamingClient } = await import(
        "../services/amplifyService"
      );
      await createTranscribeStreamingClient();
    } catch (error) {
      console.error("AWS Transcribe StreamingåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼:", error);
    }
  };

  const startTranscribeStreamingProcess = async () => {
    if (!mediaStreamRef.current) return;

    try {
      transcribeAbortControllerRef.current = new AbortController();
      console.log("AWS Transcribe Streamingé–‹å§‹");

      await startTranscribeStreaming(
        mediaStreamRef.current,
        (text: string, isFinal: boolean) => {
          if (isFinal) {
            if (text.trim()) {
              accumulatedTranscriptRef.current += text + " ";
              console.log("æœ€çµ‚çµæœè¿½åŠ :", text);
            }
            setTimeout(() => {
              onTranscriptionResult?.(accumulatedTranscriptRef.current);
            }, 100);
          } else {
            if (text.trim()) {
              const displayText = accumulatedTranscriptRef.current + text;
              setTimeout(() => {
                onTranscriptionResult?.(displayText);
              }, 200);
            }
          }
        },
        () => isStoppedManuallyRef.current
      );

      console.log("AWS Transcribe Streamingçµ‚äº†");
    } catch (error) {
      console.error("AWS Transcribe Streamingã‚¨ãƒ©ãƒ¼:", error);
    }
  };

  const handleButtonClick = async () => {
    if (isRecording) {
      console.log("ğŸ›‘ éŒ²éŸ³åœæ­¢é–‹å§‹");
      isStoppedManuallyRef.current = true;

      if (transcribeAbortControllerRef.current) {
        transcribeAbortControllerRef.current.abort();
        transcribeAbortControllerRef.current = null;
      }

      if (mediaStreamRef.current) {
        mediaStreamRef.current.getTracks().forEach((track) => track.stop());
        mediaStreamRef.current = null;
      }

      accumulatedTranscriptRef.current = "";
      setIsRecording(false);
    } else {
      console.log("ğŸ¤ éŒ²éŸ³é–‹å§‹");
      isStoppedManuallyRef.current = false;
      accumulatedTranscriptRef.current = "";

      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          audio: {
            sampleRate: 16000,
            channelCount: 1,
            echoCancellation: true,
            noiseSuppression: true,
          },
        });
        mediaStreamRef.current = stream;

        setIsRecording(true);

        startTranscribeStreamingProcess().catch((error) => {
          console.error("Transcribe Streamingé–‹å§‹ã‚¨ãƒ©ãƒ¼:", error);
        });
      } catch (err) {
        console.error("éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ å–å¾—ã‚¨ãƒ©ãƒ¼:", err);
        setIsRecording(false);
      }
    }
  };

  useEffect(() => {
    if (!isInitializedRef.current) {
      initializeRecorder();
      isInitializedRef.current = true;
    }
  }, []);

  // éŒ²éŸ³çŠ¶æ…‹å¤‰æ›´ã‚’ç›£è¦–ã—ã¦é©åˆ‡ãªå‡¦ç†ã‚’å®Ÿè¡Œ
  const isFirstRenderRef = useRef(true);
  const prevIsRecordingRef = useRef(false);

  useEffect(() => {
    if (isFirstRenderRef.current) {
      isFirstRenderRef.current = false;
      prevIsRecordingRef.current = isRecording;
      return;
    }

    // çŠ¶æ…‹ãŒå®Ÿéš›ã«å¤‰æ›´ã•ã‚ŒãŸå ´åˆã®ã¿å‡¦ç†ã‚’å®Ÿè¡Œ
    if (prevIsRecordingRef.current !== isRecording) {
      console.log(
        `ğŸ”„ éŒ²éŸ³çŠ¶æ…‹å¤‰æ›´: ${prevIsRecordingRef.current} â†’ ${isRecording}`
      );
      if (isRecording) {
        // éŒ²éŸ³é–‹å§‹æ™‚ï¼šç©ºæ–‡å­—åˆ—ã‚’é€ä¿¡
        onTranscriptionResult?.("");
      }
      prevIsRecordingRef.current = isRecording;
    }
  }, [isRecording]);

  return (
    <Box
      sx={{
        display: "flex",
        flexDirection: "column",
        alignItems: "center",
        gap: 2,
      }}
    >
      <Tooltip title={isRecording ? "éŒ²éŸ³åœæ­¢" : "éŒ²éŸ³é–‹å§‹"}>
        <IconButton
          onClick={handleButtonClick}
          disabled={disabled}
          sx={{
            backgroundColor: isRecording ? "#ff5252" : "#4caf50",
            color: "white",
            width: "40px",
            height: "40px",
            minWidth: "40px",
            "&:hover": {
              backgroundColor: isRecording ? "#d32f2f" : "#388e3c",
            },
            "&:disabled": {
              backgroundColor: "#ccc",
            },
          }}
        >
          {isRecording ? <StopIcon /> : <MicIcon />}
        </IconButton>
      </Tooltip>
    </Box>
  );
};

export default memo(VoiceRecorder);
